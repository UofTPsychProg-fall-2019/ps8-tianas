rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
df < data %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
data[is.na(data)]
data %>%
data %>%
data <- read.csv("~/Downloads/emdata.csv")
View(data)
View(data)
data <- read.csv("~/Downloads/emdata.csv")
data %>%
data
data
data %>%
group_by(AVERAGE_IA_7_SAMPLE_COUNT_.)
filter(ANTIC == 0 | BIN_INDEX < 10 )
data %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
data %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Bar Chart"
)
# NOTE ON READING THE DATA:
# measurements are taken from the description onset. We excluded all data under 200 ms in order to minimize outliers/null data.
# Bins are 50 ms each starting from the sentential description onset (i.e., "Move the [DESC_ONSET] other house...")
# Data + Libraries --------------------------------------------------------
data <- read.csv("~/Downloads/emdata.csv")
library(ggplot2)
library(car)
library(rpivotTable)
library(dplyr)
# Probability of fixation ------------------------------------------------------------
# Note that these pivot tables are included to emulate how I will pivot the data in Excel before I import the pivoted data into R for analysis.
# I do like the rpivotTable package, but it doesn't include a function to export the data into a data frame, rendering the outcome a bit pointless
# beyond a quick look at the data. When I'm actually visualizing my data, I will stick with the Excel/import to R method.
## Pivot table to look at probability of fixation over time.
data %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows="BIN_INDEX",
cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
## Make a chart to look at the data!
data %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows=c("nptype","givennew"),
cols="BIN_INDEX",
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Line Chart"
)
# Central summary measures ------------------------------------------------
## averages
data %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
## Plotting the averages to look at likelihood of fixating on the previously-mentioned object
## Note: this is just a quick look. When I actually visualize my data, I'll include error bars!
data %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Bar Chart"
)
# Analysis ----------------------------------------------------------------
# ANOVAs --------------------------------------
# RT
anova(lm(rt ~ partofspeech*object, data))
Anova(lm(rt ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# Choosing previously-mentioned object
anova(lm(selobj_same ~ partofspeech*object, data))
Anova(lm(selobj_same ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# Likelihood of fixation on previously-mentioned object
anova(lm(fixation_same ~ partofspeech*object, data))
Anova(lm(fixation_same ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# contrasts -----------------------------------
data$pronoun[0:23] <- -1
data$pronoun[23:44] <- 1
data$newObj[0:44] <- 1
data$newObj[12:44] <- -1
data$newObj[23:44] <- 1
data$newObj[34:44] <- -1
# add to table and reorganize
data$interaction <- (data$pronoun)*(data$newObj)
anova(lm(fixation_same ~ pronoun*newObj, data))
# RT plot -----------------------------------------------------------------
ggplot(data, aes(x = partofspeech, y = rt, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-speech", y=expression(paste("Reaction time")), title="RT vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
# Selected previously-mentioned object? -----------------------------------
ggplot(data, aes(x = partofspeech, y = selobj_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Choosing PMO (1=yes)")), title="Choosing PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
# Likelihood of fixation on previously-mentioned object -------------------
ggplot(data, aes(x = partofspeech, y = fixation_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Likelihood of fixation on PMO")), title="Fixation on PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
View(data)
# NOTE ON READING THE DATA:
# measurements are taken from the description onset. We excluded all data under 200 ms in order to minimize outliers/null data.
# Bins are 50 ms each starting from the sentential description onset (i.e., "Move the [DESC_ONSET] other house...")
# Data + Libraries --------------------------------------------------------
df <- read.csv("~/Downloads/emdata.csv")
library(ggplot2)
library(car)
library(rpivotTable)
library(dplyr)
# Probability of fixation ------------------------------------------------------------
# Note that these pivot tables are included to emulate how I will pivot the data in Excel before I import the pivoted data into R for analysis.
# I do like the rpivotTable package, but it doesn't include a function to export the data into a data frame, rendering the outcome a bit pointless
# beyond a quick look at the data. When I'm actually visualizing my data, I will stick with the Excel/import to R method.
## Pivot table to look at probability of fixation over time.
df %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows="BIN_INDEX",
cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
## Make a chart to look at the data!
df %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows=c("nptype","givennew"),
cols="BIN_INDEX",
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Line Chart"
)
# Central summary measures ------------------------------------------------
## averages
df %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
## Plotting the averages to look at likelihood of fixating on the previously-mentioned object
## Note: this is just a quick look. When I actually visualize my data, I'll include error bars!
df %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Bar Chart"
)
# Analysis ----------------------------------------------------------------
data <- read.csv("~/Downloads/exp1data.csv")
# ANOVAs --------------------------------------
# RT
anova(lm(rt ~ partofspeech*object, data))
Anova(lm(rt ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# Choosing previously-mentioned object
anova(lm(selobj_same ~ partofspeech*object, data))
Anova(lm(selobj_same ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# Likelihood of fixation on previously-mentioned object
anova(lm(fixation_same ~ partofspeech*object, data))
Anova(lm(fixation_same ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# contrasts -----------------------------------
data$pronoun[0:23] <- -1
data$pronoun[23:44] <- 1
data$newObj[0:44] <- 1
data$newObj[12:44] <- -1
data$newObj[23:44] <- 1
data$newObj[34:44] <- -1
# add to table and reorganize
data$interaction <- (data$pronoun)*(data$newObj)
anova(lm(fixation_same ~ pronoun*newObj, data))
# RT plot -----------------------------------------------------------------
ggplot(data, aes(x = partofspeech, y = rt, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-speech", y=expression(paste("Reaction time")), title="RT vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
# Selected previously-mentioned object? -----------------------------------
ggplot(data, aes(x = partofspeech, y = selobj_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Choosing PMO (1=yes)")), title="Choosing PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
# Likelihood of fixation on previously-mentioned object -------------------
ggplot(data, aes(x = partofspeech, y = fixation_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Likelihood of fixation on PMO")), title="Fixation on PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
df %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows="BIN_INDEX",
cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
df %>%
tbl_df %>%
filter( ANTIC == 0) %>%
rpivotTable(rows=c("nptype","givennew"),
cols="BIN_INDEX",
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Line Chart"
)
df %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
df %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Bar Chart"
)
data <- read.csv("~/Downloads/exp1data.csv")
# RT
anova(lm(rt ~ partofspeech*object, data))
Anova(lm(rt ~ partofspeech * object, data=data, contrasts=list(partofspeech=contr.sum, object=contr.sum)), type=3)
# Contrast Coding --------------------------------
data$pronoun[0:23] <- -1
data$pronoun[23:44] <- 1
data$newObj[0:44] <- 1
data$newObj[12:44] <- -1
data$newObj[23:44] <- 1
data$newObj[34:44] <- -1
data$interaction <- (data$pronoun)*(data$newObj)
anova(lm(fixation_same ~ pronoun*newObj, data))
ggplot(data, aes(x = partofspeech, y = rt, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-speech", y=expression(paste("Reaction time")), title="RT vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
ggplot(data, aes(x = partofspeech, y = selobj_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Choosing PMO (1=yes)")), title="Choosing PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
ggplot(data, aes(x = partofspeech, y = fixation_same, colour = object, fill=object)) +
stat_summary(fun.y = mean, geom = "bar", position = "dodge", alpha=.2) +
geom_point(position = position_jitterdodge(), alpha=.4) +
stat_summary(fun.data = mean_se, geom = "errorbar",
width = .1, position = position_dodge(width = .9))+
theme_bw() +
labs(x="Part-of-Speech", y=expression(paste("Likelihood of fixation on PMO")), title="Fixation on PMO vs. part-of-speech, by object condition") +
theme(plot.title = element_text(hjust = 0.5)) +
theme(plot.title = element_text(face="bold"))
df %>%
tbl_df %>%
filter( ANTIC == 0, BIN_INDEX < 10) %>%
rpivotTable(cols=c("nptype","givennew"),
aggregatorName="Average",
vals ="AVERAGE_IA_7_SAMPLE_COUNT_.",
rendererName="Table"
)
setwd("~/Downloads/Lec9")
# loading libraries  ---------------------------------------------
# remember: you can create labeled code sections by inserting 4 - at the end of a comment line
# or press ctrl shift R
library(tidyverse)
------------------------------------------
library(tidyverse)
# reading in IAT data  ---------------------------------------------
# use a tidyverse function to read in the included IAT_2019.csv file
tbl <- read_csv("IAT.csv")
# Removing unnecessary rows and columns  ---------------------------------------------
# This data frame only contains 21 of the 454 available variables, but it's still too much
# use tidyverse functions so that only the following variables are included: 'session_id',"genderidentity","raceomb_002","D_biep.White_Good_all","Mn_RT_all_3467",
#       "edu_14","politicalid_7","STATE","att_7","tblacks_0to10","twhites_0to10","labels"
tbl_clean <- select(tbl, -c(13:21))
#### assuming that "genderidentity" means the "gender" column
# next, clean up the rows
# our primary dependent variable is D_biep.White_Good_all, but some subjects
# don't have any data. Remove the rows with missing D_biep.White_Good_all entries
tbl_clean <- drop_na(tbl_clean, D_biep.White_Good_all)
# Renaming varialbles  ---------------------------------------------
# next rename variables with more intuitive, short labels
# here are some suggestions (along with variable info)
# id : session_id (subject number)
# gender : genderidentity (gender 1 "Male" 2 "Female" 3 "Trans male/Trans man" 4 "Trans female/Trans woman" 5 "Genderqueer/Gender nonconforming" 6 "A different identity")
# race : raceomb_002 (race: 1 "American Indian" 2 "East Asian" 3 "South Asian" 4 "Hawaiian Pacifica Islander" 5 "black Africian American" 6 "white" 7 "other" 8 "multiracial")
# bias :D_biep.White_Good_all (overall IAT score)
# rt : Mn_RT_all_3467 (overall reaction time)
# edu : edu_14 (education: 1 "elementary" 2 "junior high" 3 "some high school" 4 "HS grad" 5 "some college" 6 "associate's" 7 "bachelor's" 8 "some grad" 9 "MA" 10 "JD" 11 "MD" 12 "PHD" 13 "other advanced" 14 "MBA")
# pol : politicalid_7 (political identification: 1 "strongly conservative 7 "strongly liberal)
# state : STATE
# att : att_7 (race attitude 1 "strongly prefer AA" 7 "strongly prefer white")
# temp_b : tblacks_0to10 (temperature feelings black 1 "extremely cold" 10 "extremly warm")
# temp_w : twhites_0to10 (temperature feelings black 1 "extremely cold" 10 "extremly warm")
tbl_clean <- rename(tbl_clean,
id=session_id,
race=raceomb_002,
bias=D_biep.White_Good_all,
rt=Mn_RT_all_3467,
edu=edu_14,
pol=politicalid_7,
state=STATE,
att=att_7,
temp_b=tblacks_0to10,
temp_w=twhites_0to10
)
tbl_clean$gender <- recode(tbl_clean$gender,
`[1]`= "Male",
`[2]`= "Female",
`[3]` = "Trans male/Trans man",
`[4]` = "Trans female/Trans woman",
`[5]` = "Genderqueer/Gender nonconforming",
`[6]` = "A different identity",
)
# loading libraries  ---------------------------------------------
library(tidyverse)
# reading in IAT data  ---------------------------------------------
# use a tidyverse function to read in the included IAT_2019.csv file
tbl <- read_csv("IAT.csv")
# Removing unnecessary rows and columns  ---------------------------------------------
# This data frame only contains 21 of the 454 available variables, but it's still too much
# use tidyverse functions so that only the following variables are included: 'session_id',"genderidentity","raceomb_002","D_biep.White_Good_all","Mn_RT_all_3467",
#       "edu_14","politicalid_7","STATE","att_7","tblacks_0to10","twhites_0to10","labels"
tbl_clean <- select(tbl, -c(13:21))
setwd("~/Documents/ps8-tianas")
# loading libraries  ---------------------------------------------
library(tidyverse)
# reading in IAT data  ---------------------------------------------
# use a tidyverse function to read in the included IAT_2019.csv file
tbl <- read_csv("IAT.csv")
# Removing unnecessary rows and columns  ---------------------------------------------
# This data frame only contains 21 of the 454 available variables, but it's still too much
# use tidyverse functions so that only the following variables are included: 'session_id',"genderidentity","raceomb_002","D_biep.White_Good_all","Mn_RT_all_3467",
#       "edu_14","politicalid_7","STATE","att_7","tblacks_0to10","twhites_0to10","labels"
tbl_clean <- select(tbl, -c(13:21))
# loading libraries  ---------------------------------------------
library(tidyverse)
# reading in IAT data  ---------------------------------------------
# use a tidyverse function to read in the included IAT_2019.csv file
tbl <- read_csv("IAT.csv")
# Removing unnecessary rows and columns  ---------------------------------------------
# This data frame only contains 21 of the 454 available variables, but it's still too much
# use tidyverse functions so that only the following variables are included: 'session_id',"genderidentity","raceomb_002","D_biep.White_Good_all","Mn_RT_all_3467",
#       "edu_14","politicalid_7","STATE","att_7","tblacks_0to10","twhites_0to10","labels"
tbl_clean <- select(tbl, -c(13:21))
(temperature feelings black 1 "extremely cold" 10 "extremly warm")
# temp_w : twhites_0to10 (temperature feelings black 1 "extremely cold" 10 "extremly warm")
tbl_clean <- rename(tbl_clean,
id=session_id,
race=raceomb_002,
bias=D_biep.White_Good_all,
rt=Mn_RT_all_3467,
edu=edu_14,
pol=politicalid_7,
state=STATE,
att=att_7,
temp_b=tblacks_0to10,
temp_w=twhites_0to10
)
tbl_clean$gender <- recode(tbl_clean$gender,
`[1]`= "Male",
`[2]`= "Female",
`[3]` = "Trans male/Trans man",
`[4]` = "Trans female/Trans woman",
`[5]` = "Genderqueer/Gender nonconforming",
`[6]` = "A different identity",
)
# next, clean up the rows
# our primary dependent variable is D_biep.White_Good_all, but some subjects
# don't have any data. Remove the rows with missing D_biep.White_Good_all entries
tbl_clean <- drop_na(tbl_clean, D_biep.White_Good_all)
# loading libraries  ---------------------------------------------
library(tidyverse)
# reading in IAT data  ---------------------------------------------
# use a tidyverse function to read in the included IAT_2019.csv file
tbl <- read_csv("IAT.csv")
# Removing unnecessary rows and columns  ---------------------------------------------
# This data frame only contains 21 of the 454 available variables, but it's still too much
# use tidyverse functions so that only the following variables are included: 'session_id',"genderidentity","raceomb_002","D_biep.White_Good_all","Mn_RT_all_3467",
#       "edu_14","politicalid_7","STATE","att_7","tblacks_0to10","twhites_0to10","labels"
tbl_clean <- select(tbl, -c(13:21))
#### assuming that "genderidentity" means the "gender" column
# next, clean up the rows
# our primary dependent variable is D_biep.White_Good_all, but some subjects
# don't have any data. Remove the rows with missing D_biep.White_Good_all entries
tbl_clean <- drop_na(tbl_clean, D_biep.White_Good_all)
tbl_clean <- rename(tbl_clean,
id=session_id,
race=raceomb_002,
bias=D_biep.White_Good_all,
rt=Mn_RT_all_3467,
edu=edu_14,
pol=politicalid_7,
state=STATE,
att=att_7,
temp_b=tblacks_0to10,
temp_w=twhites_0to10
)
tbl_clean$gender <- recode(tbl_clean$gender,
`[1]`= "Male",
`[2]`= "Female",
`[3]` = "Trans male/Trans man",
`[4]` = "Trans female/Trans woman",
`[5]` = "Genderqueer/Gender nonconforming",
`[6]` = "A different identity",
)
View(tbl_clean)
tbl_clean$race <- recode(tbl_clean$race,
`1`= "American Indian",
`2`= "East Asian",
`3` = "South Asian",
`4` = "Hawaiian Pacific Islander",
`5` = "black African American",
`6` = "white",
`7` = "other",
`8` = "multiracial"
)
View(tbl_clean)
tbl_clean$edu <- recode(tbl_clean$edu,
`1`= "elementary",
`2`= "junior high",
`3` = "some high school",
`4` = "HS grad",
`5` = "some college",
`6` = "associate's",
`7` = "bachelor's",
`8` = "some grad",
`9` = "MA",
`10` = "JD",
`11` = "MD",
`12` = "PhD",
`13` = "other advanced",
`14` = "MBA"
)
View(tbl_clean)
summary(tbl_clean)
tbl_clean$gender <- drop_na(gender)
tbl_clean$gender <- drop_na(tbl_clean$gender)
